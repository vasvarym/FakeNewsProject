{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "import nltk\n",
    "import re\n",
    "# Import word_tokenize and stopwords from nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, f1_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Conv1D, MaxPool1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of TRAIN DATA:  (10240, 2)\n",
      "Shape of TEST DATA:  (2551, 2)\n"
     ]
    }
   ],
   "source": [
    "# Shape of each set\n",
    "\n",
    "print(\"Shape of TRAIN DATA: \", train.shape)\n",
    "print(\"Shape of TEST DATA: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Building a wall on the U.S.-Mexico border will...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Wisconsin is on pace to double the number of l...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Says John McCain has done nothing to help the ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suzanne Bonamici supports a plan that will cut...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>When asked by a reporter whether hes at the ce...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Statement  Label\n",
       "0  Building a wall on the U.S.-Mexico border will...   True\n",
       "1  Wisconsin is on pace to double the number of l...  False\n",
       "2  Says John McCain has done nothing to help the ...  False\n",
       "3  Suzanne Bonamici supports a plan that will cut...   True\n",
       "4  When asked by a reporter whether hes at the ce...  False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Statement  Label\n",
       "0  Says the Annies List political group supports ...  False\n",
       "1  When did the decline of coal start? It started...   True\n",
       "2  Hillary Clinton agrees with John McCain \"by vo...   True\n",
       "3  Health care reform legislation is likely to ma...  False\n",
       "4  The economic turnaround started at the end of ...   True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the original Data for future\n",
    "\n",
    "train_orig = train.copy()\n",
    "test_orig = test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_statements(text):\n",
    "    \n",
    "    # Tokenize the words\n",
    "    tokenized = word_tokenize(text)\n",
    "\n",
    "    # Remove the stop words\n",
    "    tokenized = [token for token in tokenized if token not in stopwords.words(\"english\")] \n",
    "\n",
    "    # Lemmatize the words, changing text to lowercase\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokenized = [lemmatizer.lemmatize(token.lower(), pos='a') for token in tokenized]\n",
    "\n",
    "    # Remove non-alphabetic characters and keep the words contains three or more letters\n",
    "    tokenized = [token for token in tokenized if token.isalpha() and len(token)>2]\n",
    "    \n",
    "    return tokenized\n",
    "    \n",
    "# Call the function and store the result into a new column\n",
    "#train[\"Processed\"] = train['Statement'].str.lower().apply(process_statements)\n",
    "\n",
    "# Print the first fifteen rows of Processed\n",
    "#display(train[[\"Processed\"]].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def tokenize(self, tokenizer=nltk.word_tokenize):\n",
    "        def tokenize_row(row):\n",
    "            row[\"text\"] = tokenizer(row[\"text\"])\n",
    "            row[\"tokenized_text\"] = [] + row[\"text\"]\n",
    "            return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Statement</th>\n",
       "      <th>Label</th>\n",
       "      <th>Processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Says the Annies List political group supports ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[says, annies, list, political, group, support...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When did the decline of coal start? It started...</td>\n",
       "      <td>True</td>\n",
       "      <td>[decline, coal, start, started, natural, gas, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hillary Clinton agrees with John McCain \"by vo...</td>\n",
       "      <td>True</td>\n",
       "      <td>[hillary, clinton, agrees, john, mccain, votin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Health care reform legislation is likely to ma...</td>\n",
       "      <td>False</td>\n",
       "      <td>[health, care, reform, legislation, likely, ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The economic turnaround started at the end of ...</td>\n",
       "      <td>True</td>\n",
       "      <td>[economic, turnaround, started, end, term]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Statement  Label  \\\n",
       "0  Says the Annies List political group supports ...  False   \n",
       "1  When did the decline of coal start? It started...   True   \n",
       "2  Hillary Clinton agrees with John McCain \"by vo...   True   \n",
       "3  Health care reform legislation is likely to ma...  False   \n",
       "4  The economic turnaround started at the end of ...   True   \n",
       "\n",
       "                                           Processed  \n",
       "0  [says, annies, list, political, group, support...  \n",
       "1  [decline, coal, start, started, natural, gas, ...  \n",
       "2  [hillary, clinton, agrees, john, mccain, votin...  \n",
       "3  [health, care, reform, legislation, likely, ma...  \n",
       "4         [economic, turnaround, started, end, term]  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#Train test split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(train[\"Statement\"], train[\"Label\"], test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train[\"Statement\"]\n",
    "X_test = test[\"Statement\"]\n",
    "y_train = train[\"Label\"]\n",
    "y_test = test[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text so the models can actually interpret it\n",
    "vectorizer = TfidfVectorizer(analyzer=process_statements)\n",
    "x_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "x_test_vectorized = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10240, 11179)\n",
      "(2551, 11179)\n",
      "(10240,)\n",
      "(2551,)\n"
     ]
    }
   ],
   "source": [
    "print (x_train_vectorized.shape)\n",
    "print (x_test_vectorized.shape)\n",
    "print (y_train.shape)\n",
    "print (y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression accuracy: 0.6095648765190121\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(x_train_vectorized, y_train)\n",
    "logR_predicted = log_reg.predict(x_test_vectorized)\n",
    "print(f\"{log_reg.__class__.__name__} accuracy: {log_reg.score(x_test_vectorized, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.46      0.52      1169\n",
      "        True       0.62      0.74      0.67      1382\n",
      "\n",
      "    accuracy                           0.61      2551\n",
      "   macro avg       0.61      0.60      0.60      2551\n",
      "weighted avg       0.61      0.61      0.60      2551\n",
      "\n",
      "\n",
      "\n",
      "[[ 537  632]\n",
      " [ 364 1018]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, logR_predicted))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test, logR_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier accuracy: 0.587890625\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=10, max_depth=100)\n",
    "random_forest.fit(x_train_vectorized, y_train)\n",
    "\n",
    "print(f\"{random_forest.__class__.__name__} accuracy: {random_forest.score(x_test_vectorized, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.51      0.41      0.45      1065\n",
      "        True       0.63      0.72      0.67      1495\n",
      "\n",
      "    accuracy                           0.59      2560\n",
      "   macro avg       0.57      0.56      0.56      2560\n",
      "weighted avg       0.58      0.59      0.58      2560\n",
      "\n",
      "\n",
      "\n",
      "[[ 434  631]\n",
      " [ 424 1071]]\n"
     ]
    }
   ],
   "source": [
    "rForest_pred = random_forest.predict(x_test_vectorized)\n",
    "print(classification_report(y_test, rForest_pred))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test, rForest_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB accuracy: 0.6203125\n"
     ]
    }
   ],
   "source": [
    "multi_nb = MultinomialNB()\n",
    "multi_nb.fit(x_train_vectorized, y_train)\n",
    "print(f\"{multi_nb.__class__.__name__} accuracy: {multi_nb.score(x_test_vectorized, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.29      0.39      1065\n",
      "        True       0.63      0.85      0.72      1495\n",
      "\n",
      "    accuracy                           0.62      2560\n",
      "   macro avg       0.61      0.57      0.56      2560\n",
      "weighted avg       0.61      0.62      0.59      2560\n",
      "\n",
      "\n",
      "\n",
      "[[ 312  753]\n",
      " [ 219 1276]]\n"
     ]
    }
   ],
   "source": [
    "NaiveB_pred = multi_nb.predict(x_test_vectorized)\n",
    "print(classification_report(y_test, NaiveB_pred))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test, NaiveB_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC accuracy: 0.58515625\n"
     ]
    }
   ],
   "source": [
    "svm = svm.LinearSVC()\n",
    "svm.fit(x_train_vectorized, y_train)\n",
    "print(f\"{svm.__class__.__name__} accuracy: {svm.score(x_test_vectorized, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.48      0.49      1065\n",
      "        True       0.64      0.66      0.65      1495\n",
      "\n",
      "    accuracy                           0.59      2560\n",
      "   macro avg       0.57      0.57      0.57      2560\n",
      "weighted avg       0.58      0.59      0.58      2560\n",
      "\n",
      "\n",
      "\n",
      "[[509 556]\n",
      " [506 989]]\n"
     ]
    }
   ],
   "source": [
    "svm_pred = svm.predict(x_test_vectorized)\n",
    "\n",
    "print(classification_report(y_test, svm_pred))\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test, svm_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM  (To Be Done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_NB_WORDS = 100000 # max number of words for tokenizer\n",
    "MAX_SEQUENCE_LENGTH = 1000 # max length of each sentences, including padding\n",
    "VALIDATION_SPLIT = 0.2 # 20% of data for validation (not used in training)\n",
    "EMBEDDING_DIM = 100 # embedding dimensions for word vectors\n",
    "\n",
    "#Creating Word Vectors by Word2Vec Method (takes time...)\n",
    "#w2v_model = Word2Vec(sentences=X, size=EMBEDDING_DIM, window=5, min_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 12408\n"
     ]
    }
   ],
   "source": [
    "y_train = train[\"Label\"].values\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS)\n",
    "tokenizer.fit_on_texts(train['Statement'])\n",
    "sequences = tokenizer.texts_to_sequences(train['Statement'])\n",
    "word_index = tokenizer.word_index\n",
    "print(\"Vocabulary size:\", len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Padding\n",
    "Now we are going to add padding to our data to make it uniform. Keras makes it easy to pad our data by using pad_sequences function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(sequences,maxlen = 1000, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(test_sequences,maxlen = 1000,padding='post', truncating='post')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
